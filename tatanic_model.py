# -*- coding: utf-8 -*-
"""Tatanic_model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DEWOzFsm1Hne7XcQ5-RtO9YNex_JOcSR
"""

import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

titanic=sns.load_dataset('titanic')

print(titanic.head())

print(titanic.isnull().sum())

plt.figure(figsize=(6,4))
sns.heatmap(titanic.isnull(),
cbar=False,cmap='viridis')
plt.title('null value in titanic dataset')
plt.show|()

missing_values = titanic.isnull().sum()
missing_values = missing_values[missing_values > 0]

# Bar plot
plt.figure(figsize=(6, 4))
missing_values.plot(kind='bar', color='skyblue')
plt.title("Count of Missing Values in Each Column")
plt.xlabel("Columns")
plt.ylabel("Number of Missing Values")
plt.show()

# Pclass ke hisaab se mean age
mean_ages = titanic.groupby('pclass')['age'].mean()
print(mean_ages)

plt.figure(figsize=(8, 5))
sns.barplot(x=mean_ages.index, y=mean_ages.values, palette="pastel")
plt.title("Mean Age by Passenger Class")
plt.xlabel("Passenger Class")
plt.ylabel("Mean Age")
plt.show()

# Apply function to fill null values
def fill_age(row):
    if pd.isnull(row['age']):
        if row['pclass'] == 1:
            return mean_ages[1]
        elif row['pclass'] == 2:
            return mean_ages[2]
        else:
            return mean_ages[3]
    else:
        return row['age']

# Apply function to dataset
titanic['age'] = titanic.apply(fill_age, axis=1)

print(titanic.isnull().sum())

plt.figure(figsize=(8, 5))
sns.histplot(titanic['age'], kde=True, color="red")
plt.title("Age Distribution (Before Filling)")
plt.show()

columns_to_drop = ['class', 'who', 'adult_male', 'deck', 'alive', 'embark_town']

# Drop unnecessary columns
titanic_cleaned = titanic.drop(columns=columns_to_drop, errors='ignore')

# Verify remaining columns
print(titanic_cleaned.columns)

from sklearn.preprocessing import LabelEncoder

# Encode 'sex' column
titanic_cleaned['sex'] = LabelEncoder().fit_transform(titanic_cleaned['sex'])

# Encode 'embarked' column
titanic_cleaned['embarked'] = LabelEncoder().fit_transform(titanic_cleaned['embarked'])

# Features (X) and target (y)
X = titanic_cleaned.drop(columns=['survived'])  # Remove target column
y = titanic_cleaned['survived']

from sklearn.model_selection import train_test_split

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression

# Initialize and train the model
log_model = LogisticRegression()
log_model.fit(X_train, y_train)

#Predict on test data
y_pred=log_model.predict(X_test)

from sklearn.metrics import accuracy_score

# Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

from sklearn.metrics import classification_report

# Detailed report
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier

# Initialize and train Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Predictions and evaluation
y_pred_rf = rf_model.predict(X_test)

# Accuracy and metrics
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

import pickle

# Save the trained model
with open('titanic_logistic_model.pkl', 'wb') as file:
    pickle.dump(log_model, file)